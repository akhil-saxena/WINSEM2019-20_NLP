{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #import all the required stemmers\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mList of Supported Languages by Snowball Stemmer:\n",
      "\u001b[0m\n",
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n",
      "\u001b[1mTotal languages supported by Snowball:\n",
      "\u001b[0m\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "PS=PorterStemmer() \n",
    "LS=LancasterStemmer()\n",
    "SS= SnowballStemmer('english') #Since Snowball is multilingual, we specify the language we are using.\n",
    "LZ=WordNetLemmatizer()\n",
    "print('\\033[1m'+'List of Supported Languages by Snowball Stemmer:')\n",
    "print('\\033[0m')\n",
    "print(SnowballStemmer.languages)\n",
    "print('\\033[1m'+'Total languages supported by Snowball:')\n",
    "print('\\033[0m')\n",
    "print(len(SnowballStemmer.languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGiven Word\tPorter\t\tLancaster\tSnowball\tLemmatizer\n",
      "\u001b[0mbeautiful:\tbeauti\t\tbeauty\t\tbeauti\t\tbeautiful\n",
      "\u001b[0mplayful:\tplay\t\tplay\t\tplay\t\tplayful\n",
      "\u001b[0mlightly:\tlightli\t\tlight\t\tlight\t\tlightly\n",
      "\u001b[0mmeticulously:\tmeticul\t\tmetic\t\tmeticul\t\tmeticulously\n",
      "\u001b[0mamazing:\tamaz\t\tamaz\t\tamaz\t\tamaze\n",
      "\u001b[0mceasing:\tceas\t\tceas\t\tceas\t\tcease\n",
      "\u001b[0mlemmatization:\tlemmat\t\tlem\t\tlemmat\t\tlemmatization\n",
      "\u001b[0mreplacement:\treplac\t\treplac\t\treplac\t\treplacement\n",
      "\u001b[0mdependent:\tdepend\t\tdepend\t\tdepend\t\tdependent\n",
      "\u001b[0mfascism:\tfascism\t\tfasc\t\tfascism\t\tfascism\n"
     ]
    }
   ],
   "source": [
    "word_list=['beautiful', 'playful', 'lightly', 'meticulously', 'amazing', 'ceasing', 'lemmatization', 'replacement', 'dependent', 'fascism']\n",
    "print('\\033[1m'+'Given Word\\tPorter\\t\\tLancaster\\tSnowball\\tLemmatizer')\n",
    "for word in word_list:\n",
    "    print('\\033[0m'+ word +':' +'\\t'+ PS.stem(word) +'\\t\\t'+ LS.stem(word) + '\\t\\t' + SS.stem(word) + '\\t\\t'+ LZ.lemmatize(word,pos='v') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can conclude that none of the stemmers are very effective, but each has its own benefits.\n",
    "# Though Porter Stemmer is the most primitive stemmer, some words are better handled by this compared to Lancaster Stemmer.\n",
    "# Eg. Lemmatization -> lemmat, Fascism -> fascism (Porter Stemmer) // Correct \n",
    "# Eg. Lemmatization -> lem (Lancaster Stemmer), Fascism -> fasc // Incorrect\n",
    "\n",
    "# Snowball Stemmer is the only one which supports multiple languages. (16 languages)\n",
    "\n",
    "# WordNetLemmatizer is effective most of the time since it reduces the word to its lemma by referencing a dictionary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
